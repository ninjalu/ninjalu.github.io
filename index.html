<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Resume - Start Bootstrap Theme</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Ninja Lu</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile-pic.jpg" alt="" /></span>
            </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#projects">projects</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#blog">blog</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Interests</a></li>
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        Ninja
                        <span class="text-primary">Lu</span>
                    </h1>
                    <div class="subheading mb-5">

                        <a href="mailto:name@email.com">ninjaluluo@gmail.com</a>
                    </div>
                    <p class="lead mb-5">I am Ninja Lu! I am passionate about data science and machine learning and committed to becoming a master of this science and art form. I am particularly interested in the exciting field of NLP and deep learning. I also take great interest in effective visualisations and communication. </p>
                    <p class="lead mb-5"> In my spare time, I enjoy gardening and have a keen eye for floristry and garden design.</p>
                    <p>Please see my LinkedIn profile and Github page through the links below:</p>
                    <div class="social-icons">
                        <a class="social-icon" href="https://www.linkedin.com/in/lu-luo-698a58191/"><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="https://github.com/ninjalu"><i class="fab fa-github"></i></a>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Experience-->
            <section class="resume-section" id="projects">
                <div class="resume-section-content">
                    <h2 class="mb-5">Projects</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Document classification for Adarga</h3>
                            <p>I developed two NLP models to classify the companyâ€™s documents as a preprocessing step to assist their downstream entity recognition tasks. I contrasted traditional NLP: hand-crafted features using spaCy and SVD of TF-IDF, achieving test F1 scores of 91% and neural NLP: BERT and RoBERTa based model achieving test F1 score of 96%. Through my approaches, I offered the company a fresh look at how by training one model, all downstream tasks can benefit.</p>
<!--                            <div class="subheading mb-3">Data</div>-->
<!--                            <p>a collection of online news and analytical articles.</p>-->
<!--                            <div class="subheading mb-3">Traditional NLP</div>-->
<!--                            <p>Handcrafted features using spaCy and SVD of TI-IDF to acheive 91% F1 score on test set.</p>-->
<!--                            <div class="subheading mb-3">Neural NLP</div>-->
<!--                            <p>BERT and RoBERTa based model to achieve test F1 score of 96%.</p>-->
                            <a href="https://github.com/ninjalu/doc-classification/blob/main/presentation.pdf">See my presentation with details and discussions here.</a> <a href="https://github.com/ninjalu/doc-classification"> Code here.</a>
                        </div>

                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Fraud detection (Kaggle)</h3>
                            <p>I built and optimised KNN, random forest, SVM and gradient boost machine on imbalanced fraud data, achieving test AUC-PR score of 84%. I designed my own custom metrics to reflex the costs of failure to detect fraud and mistaken genuine for fraud. I also explored different sampling methods and its impact on the model performance.</p>
<!--
                            <div class="subheading mb-3">Data</div>
                            <p>Transactions made by credit cards over 2 days in September 2013 by European cardholders.</p>
                            <div class="subheading mb-3">EDA</div>
                            <p>Exploratory analysis, feature extraction and engineering.</p>
                            <div class="subheading mb-3">Model building</div>
                            <p>Using over and under sampling, random search methods to build and optimise KNN, random forest, SVM, gradient boost machine, and simple neural network models; design of custom metrics to ensure business applications and interpretation.</p>
-->
                            <a href="https://github.com/ninjalu/fraud-detection/blob/main/README.md">Read more about it here.</a> <a href="https://github.com/ninjalu/fraud-detection"> Code here.</a>
                        </div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Asset clustering and portfolio optimisation (Data Science for Finance Dojo)</h3>
                            <p>For this project I performed clustering with correlation matrix and distritbution analysis on anonymous assets daily closing data from 1998 to 2019. I then used Monte Carlo simulation to optimise portfolio resulting a higher Sharpe ratio than benchmark SP500.</p>
<!--
                            
                            <div class="subheading mb-3">Data</div>
                            <p>Historical daily prices of 42 anonymous assets from 1998 to 2019.</p>
                            <div class="subheading mb-3">Asset clustering</div>
                            <p>Using correlation matrices and distribution analysis to perform clustering.</p>
                            <div class="subheading mb-3">Portfolio optimisation</div>
                            <p>Using Monte Carlo simulation to perform portfolio optimisation resulting a higher Sharpe ratio compared to SP500 benchmark.</p>
-->
                            <a href="https://github.com/ninjalu/Asset-clustering-and-portfolio-optimisation/blob/master/README.md">Read more about it here.</a> <a href="https://github.com/ninjalu/Asset-clustering-and-portfolio-optimisation"> Code here.</a>
                        </div>

                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Property recommender system (working progress)</h3>
                            <p>This project aims to build a property recommender system based on property description and images.</p>
                            <p>The inspiration for this project came out of my own frustration of not being able to search effectively, having a clear idea the kind of property I wanted, but more flexible re location. The end result from this project will be an web app where users can input some hard criterias and click on 'like' or 'dislike' of property images. The recommender will search through the database of properties currently on the market and return the best matches.</p>
<!--
                            <div class="subheading mb-3">Data</div>
                            <p>Scraped 23k property images and 1.2k property descriptions from a leading online property portal.</p>
                            <div class="subheading mb-3">Classification</div>
                            <p> Deep state-of-the-art neural network model for classifying property images in preparation for building recommender system.</p>
                            <div class="subheading mb-3">Property recommender system</div>
                            <p> Deep autoencoder to find latent representations of property characteristics; neural net recommender based on property latent representation distances; online web app for deployment (work in progress)</p>
-->
                        </div>

                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Education-->
            <section class="resume-section" id="blog">
                <div class="resume-section-content">
                    <h2 class="mb-5">blog</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Attention was all I needed!</h3>
                            <div class="subheading mb-3">A reflection on traditional NLP and BERT, pizza and sour dough</div>
                            <p>Jan 2021</p>
                            <p>Last week I finished the data science and machine learning bootcamp at AiCore. For my capstone project, I worked on a document classification problem assigned by Adarga, an AI startup with a focus on NLP solutions.Having read the task description and faced with a very small training data, I thought to myself: this can only be tackled by traditional NLP methods; training data is too small for BERT for sure.</p>
                            <p>I started handcrafting features based on the intuitions built by reading the documents in a iterative manner, entity counts, document lengths, verbs, adjectives, adverbs, etc. Before long I was getting good validation scores and SVD on TF-IDF sent the test F1 score to 91%. That's great, isn't it?</p>
                            <p>Except I still had plenty time before deadline, and I was not overly happy about my inability to capture the some of the harder-to-extract differences between classes. Things like: the tones, the writing styles, which BERT could well be very good at differienting.</p>
                            <p>Well, I still had time. No harm giving BERT a go, I thought. A couple of hours on an EC2, my test score was 94%. Then RoBERTa, which is trained on a corpus more similar to the training data, sent the score to 96%. Bingo!</p>
                            <p>That's not the end though. BERT takes much longer to train and inference. Explanability is terrible, compared to a neat feature importance produced from traditional NLP. What's the advantage except for a better performance, which some business may decide against in favour of a faster training time and explanability?</p>
                            <p>I think this is essentially a cooking problem.</p>
                            <p>What??? I hear you ask.</p>
                            <p>Think of traditional NLP vs BERT as cooking pizza vs sour dough. Pizza is fast! For most toppings, such as pepperoni and ham, you can just put straight on the bread (presume you are using premade dough). Into the oven it goes for 2 mins. Ping, ready and delicious. However, imagine for the same cooking process, you are then given some raw pepper. That's not going to get cooked in 2 mins, you need to roast it first! You say, hold on a second, I am not stupid. If I see raw peppers, of course I know the extra preprocessing it needs. But that's not what model does after you have deployed it. You might not even notice some new ingredients (raw peppers) has sneaked in! In machine learning lingo, your new data might need extra features to work, and traditional NLP methods will require you to keep an eye on the data as it comes in. Your model's continuing performance depends on it.</p>
                            <p>Now think about sour dough. There is a mother dough you grow in your fridge. Everytime, you take it out, mix with new flour, water, salt, and return a propotion of this mix dough back to the fridge. That's your new sour dough. The secret of deliciousness is not only the mother dough has been allowed to develop, but also has it seen the new ingredients. And this deliciousness carry through to all the food you made with the dough, sour dough bread, pancake, even pizza! BERT is just like that. You can routinely fine tuning your BERT parameters using the new data as it comes in, so it is kept updated on your new documents, writing styles, and vocabularies. All downstream tasks can all benefit from the updated BERT (as long as they are BERT based too), may it be classification or entity recognition, or question answering. Better still, you don't even need labelled data to fine tune BERT, AND you can almost get away with smaller amount of labelled data for downstream tasks because most of the work ('understanding' language) has been done. How good is that?</p>
                            
                            <p>What do you want to cook? Pizza or sour dough?</p>
                            <a href="https://github.com/ninjalu/doc-classification">Project code here</a>
                            
                        </div>

                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">My data science jounrey</h3>
                            <p>Aug 2020</p>
                            <p>To start my data science journey while taking care of my toddler has been far away from easy or straightfoward. There were excitement, setbacks, persistence, achievements and a lot of lack of sleep. I wouldn't change it for the world! I remember all the moments before I was about to present my work, finished late the night before, I felt proud, exhilerated and inspred. I had spring in my step! To have received positive feedbacks from fellow data scientists was the best. Now I know I can do it! I hope by sharing my <a href="https://medium.com/@luolu.renmin/my-data-science-beginning-807d0b886a34">experience</a>, I can inpire more staying at home mums to go out and embrace your next challenge, whatever it may be. It will be worth it!</p>
                        </div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Interests-->
            <section class="resume-section" id="interests">
                <div class="resume-section-content">
                    <h2 class="mb-5">Interests</h2>
                    <p>In my spare time I enjoy gardening, garden design and floral design. I won "Best Front Garden" in our community garden competition. Now I am transforming a 180 feet garden of our new home. I started arranging flowers for my friends and ultimately would love to start an enterprise of floral arranging raising money for climate change charties.</p>
                    <p class="mb-0">I am also the founder of Kingstop Piano Club, a community music group where people share their love for piano music to each other. We had our first concert in 2019. Sadly due to Covid, our planned concert in 2020 was cancelled. We look forward to our next one in central London after restrictions loosens in 2021!</p>
                    
                    <div>
                        <img style='height: 30%; width: 30%; object-fit: contain' src="assets/img/IMG_5961.PNG"/>
                        <img style='height: 30%; width: 30%; object-fit: contain' src="assets/img/IMG_5126.jpg"/>
                    </div>
                </div>
            </section>
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>

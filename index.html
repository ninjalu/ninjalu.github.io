<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>Lu Luo | data science | NLP</title>
    <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
    <!-- Font Awesome icons (free version)-->
    <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet"
        type="text/css" />
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet" />
</head>

<body id="page-top">
    <!-- Navigation-->
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">
            <span class="d-block d-lg-none">Lu Luo</span>
            <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2"
                    src="assets/img/profile.jpg" alt="" /></span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span
                class="navbar-toggler-icon"></span></button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav">
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#projects">projects</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#blog">blog</a></li>
                <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#interests">Interests</a></li>
            </ul>
        </div>
    </nav>
    <!-- Page Content-->
    <div class="container-fluid p-0">
        <!-- About-->
        <section class="resume-section" id="about">
            <div class="resume-section-content">
                <h1 class="mb-0">
                    Lu
                    <span class="text-primary">Luo</span>
                </h1>
                <div class="subheading mb-5">

                    <a href="mailto:name@email.com">ninjaluluo@gmail.com</a>
                </div>
                <p class="lead mb-5">I am Lu! I am an experienced data scientist with a keen interest in NLP and
                    finance.
                    I also take great interest in system design and communication with stakeholders. </p>
                <p class="lead mb-5"> In my spare time, I enjoy gardening and have a keen eye for floristry and garden
                    design.</p>
                <p>Please see my LinkedIn profile and Github page through the links below:</p>
                <div class="social-icons">
                    <a class="social-icon" href="https://www.linkedin.com/in/ninjaluluo/"><i
                            class="fab fa-linkedin-in"></i></a>
                    <a class="social-icon" href="https://github.com/ninjalu"><i class="fab fa-github"></i></a>
                </div>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Experience-->
        <section class="resume-section" id="projects">
            <div class="resume-section-content">
                <h2 class="mb-5">Projects</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">RAG for garden design</h3>
                        <p>Design and build a fun RAG project for plant suggestions, using Selenium, Chromadb,
                            LangChain, Llama3 and GraphRAG! Details see the blog post. Code </p>
                        <a href="https://github.com/ninjalu/plant-rag">here.</a>
                    </div>

                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Document classification for Adarga</h3>
                        <p>I developed two NLP models to classify the companyâ€™s documents as a preprocessing step to
                            assist their downstream entity recognition tasks. I contrasted traditional NLP: hand-crafted
                            features using spaCy and SVD of TF-IDF, achieving test F1 scores of 91% and neural NLP: BERT
                            and RoBERTa based model achieving test F1 score of 96%. Through my approaches, I offered the
                            company a fresh look at how by training one model, all downstream tasks can benefit.</p>
                        <!--                            <div class="subheading mb-3">Data</div>-->
                        <!--                            <p>a collection of online news and analytical articles.</p>-->
                        <!--                            <div class="subheading mb-3">Traditional NLP</div>-->
                        <!--                            <p>Handcrafted features using spaCy and SVD of TI-IDF to acheive 91% F1 score on test set.</p>-->
                        <!--                            <div class="subheading mb-3">Neural NLP</div>-->
                        <!--                            <p>BERT and RoBERTa based model to achieve test F1 score of 96%.</p>-->
                        <a href="https://github.com/ninjalu/doc-classification/blob/main/presentation.pdf">See my
                            presentation with details and discussions here.</a> <a
                            href="https://github.com/ninjalu/doc-classification"> Code here.</a>
                    </div>

                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Fraud detection (Kaggle)</h3>
                        <p>I built and optimised KNN, random forest, SVM and gradient boost machine on imbalanced fraud
                            data, achieving test AUC-PR score of 84%. I designed my own custom metrics to reflex the
                            costs of failure to detect fraud and mistaken genuine for fraud. I also explored different
                            sampling methods and its impact on the model performance.</p>
                        <!--
                            <div class="subheading mb-3">Data</div>
                            <p>Transactions made by credit cards over 2 days in September 2013 by European cardholders.</p>
                            <div class="subheading mb-3">EDA</div>
                            <p>Exploratory analysis, feature extraction and engineering.</p>
                            <div class="subheading mb-3">Model building</div>
                            <p>Using over and under sampling, random search methods to build and optimise KNN, random forest, SVM, gradient boost machine, and simple neural network models; design of custom metrics to ensure business applications and interpretation.</p>
-->
                        <a href="https://github.com/ninjalu/fraud-detection/blob/main/README.md">Read more about it
                            here.</a> <a href="https://github.com/ninjalu/fraud-detection"> Code here.</a>
                    </div>
                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Asset clustering and portfolio optimisation (Data Science for Finance Dojo)
                        </h3>
                        <p>For this project I performed clustering with correlation matrix and distribution analysis on
                            anonymous assets daily closing data from 1998 to 2019. I then used Monte Carlo simulation to
                            optimise portfolio resulting a higher Sharpe ratio than benchmark SP500.</p>
                        <!--
                            
                            <div class="subheading mb-3">Data</div>
                            <p>Historical daily prices of 42 anonymous assets from 1998 to 2019.</p>
                            <div class="subheading mb-3">Asset clustering</div>
                            <p>Using correlation matrices and distribution analysis to perform clustering.</p>
                            <div class="subheading mb-3">Portfolio optimisation</div>
                            <p>Using Monte Carlo simulation to perform portfolio optimisation resulting a higher Sharpe ratio compared to SP500 benchmark.</p>
-->
                        <a href="https://github.com/ninjalu/Asset-clustering-and-portfolio-optimisation"> Code here.</a>
                    </div>

                </div>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Education-->
        <section class="resume-section" id="blog">
            <div class="resume-section-content">
                <h2 class="mb-5">blog</h2>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">RAG for plants (Actively updating)</h3>
                        <div class="subheading mb-3">Multisearch Agent RAG for my plant hunting
                        </div>
                        <p>Oct 2024</p>
                        <p>Hasn't the field of NLP advanced so much since I left Nemo! Then the acronym "LLM" wasn't
                            much used. Of course we had been using large language models for years prior, but we (or I)
                            always used "BERT", "Transformers" or even "neural NLP".</p>
                        <p>What changed was ChatGPT suddenly brought the advances in LLM to the masses. What had used to
                            be a tool almost only know in the NLP/ML world was now a tool/toy for Joe in the convenient
                            store. And what about RAG, or Retrieval Augmented Generation? At Nemo we talked extensively
                            about building the same using meeting transcript history. "What are the key take aways from
                            the marathon of meetings on project A since April?"
                        </p>
                        <p>Since then, the technology has moved on so much while I busied myself with AML
                            solutions. We now have many more choices of open source LLMs to play with, better
                            performance and much better tooling!</p>
                        <p>LangChain for example has impressed me the most, I couldn't help having a little play with
                            it.
                        </p>
                        <p>My problem: I have for years wanted to build a tool to help me find new and interesting
                            plants that matches my criteria. Watching Gardeners' World and listening Gardeners' Question
                            Time is certainly fun, but what did Matthew Pottage said about buxus alternatives?
                        </p>
                        <p>Solution: It has to be Multisearch Agent RAG! Built with LangChain, using the vector database
                            I created from scraping Royal Horticulture Society's website and transcripts from Gardeners'
                            Question Time, Langchain's and WikipediaAPI tool.
                        </p>

                        <p>Architecture: </p>
                        <div class="img-fluid"><img src=" assets/img/ragflowchart.jpg" alt="RAG design"></div>
                        <p>First implementation was the top flow in the chart above. I scrapped all the pages from
                            <a href="https://www.rhs.org.uk/plants/search-results" target="_blank">Royal
                                Horticulture Society's plant search page</a>, and created a vector store using
                            Chromadb.
                            Then I used LangChain and Llama3 to create a retriever chain, from which I was able to
                            get
                            some decent response. My question: What's the best plant for a north facing garden with
                            clay
                            soil. I like purple flower in autumn as well as summer? Height: about 0.9m to 1.2m.
                            Please
                            list the top cultivars for autumn interest
                        </p>
                        <div class="img-fluid"><img src="assets/img/answer.png" alt="RAG answer"></div>
                        <p>This is cool. However, I am missing the growing experience from the expertise on
                            Gardeners' Question Time panel. Especially ex Wisley curator Matthew Pottage! Next step
                            adding personality and growing expertise from my favourite gardeners (To be continued)</p>


                    </div>

                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Graph is Cool</h3>
                        <div class="subheading mb-3">Some thoughts on recent work on graph databases and network
                            analysis
                        </div>
                        <p>Sep 2024</p>
                        <p>My work at Napier is sadly coming to an end in November. We are facing mass redundancy.
                            Looking back, I have had some great projects with clients, prototyped some cool
                            anti-money
                            laundering solutions, designed MLOps systems, advanced my python programming skills,
                            most
                            importantly worked with some clever yet humble people.</p>
                        <p>Amongst all my initiatives, I am the most proud of prototyping graph data science
                            solutions
                            using Neo4j from scratch. Beyond practicality of containerisation, Kubernetes and helm
                            charts etc., there are some interesting observations.</p>
                        <p>First, there is sadly a lack of high quality opensource data for product development. A
                            lot
                            of the data are very skewed towards making a point, rather than imitating what happens
                            in
                            the real world</p>
                        <p>Second, graph is powerful! With traditional supervised machine learning methods, I
                            couldn't
                            get good results, despite complex feature engineering, trialing out lots of different
                            algorithms. Graph represent the relationship so well, for one of my dataset, I got more
                            than
                            90% F1 score for one money laundering typology, all based on simple graph features. More
                            complexed typology, I needed to bring in some help from traditional ML methods such as
                            clustering to increase the accuracy. But I got good results without any advanced stuff
                            such
                            as GNN.
                        </p>
                        <p>Third, graph is hard. Hard to visualise, and hard to get a good intuition. Especially
                            when
                            the edges become really complex. What would help is designing custom metrics for
                            patterns
                            you want to look out for, that could be totally bespoke, or a combination of the
                            existing
                            metrics.</p>
                        <p>Along the way, I learned a lot in terms of graph theory and the practical side of using
                            graph
                            databases by deploying a standalone Neo4j node in our dev name space interacting with
                            the
                            service that does the data ingestion, analysis and reporting.</p>

                        <p>The future of graph sounds great. You only need to attend one of Nvidia's graph events to
                            see
                            how industry has been utilising its power. P.S. I am going to Neo4j's Graph Summit in
                            London
                            in October. Come to say hello!</p>
                        <a
                            href="https://www.napier.ai/post/network-analytics-aml?utm_content=311249811&utm_medium=social&utm_source=linkedin&hss_channel=lcp-15197985">Link
                            to the article here
                        </a>

                    </div>

                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Attention was all I needed!</h3>
                        <div class="subheading mb-3">A reflection on traditional NLP and BERT, pizza and sour dough
                        </div>
                        <p>Jan 2021</p>
                        <p>Last week I finished the data science and machine learning bootcamp at AiCore. For my
                            capstone project, I worked on a document classification problem assigned by Adarga, an
                            AI
                            startup with a focus on NLP solutions.Having read the task description and faced with a
                            very
                            small training data, I thought to myself: this can only be tackled by traditional NLP
                            methods; training data is too small for BERT for sure.</p>
                        <p>I started handcrafting features based on the intuitions built by reading the documents in
                            an
                            iterative manner, entity counts, document lengths, verbs, adjectives, adverbs, etc.
                            Before
                            long I was getting good validation scores and SVD on TF-IDF sent the test F1 score to
                            91%.
                            That's great, isn't it?</p>
                        <p>Except I still had plenty time before deadline, and I was not overly happy about my
                            inability
                            to capture the some of the harder-to-extract differences between classes. Things like:
                            the
                            tones, the writing styles, which BERT could well be very good at differentiating.</p>
                        <p>Well, I still had time. No harm giving BERT a go, I thought. A couple of hours on an EC2,
                            my
                            test score was 94%. Then RoBERTa, which is trained on a corpus more similar to the
                            training
                            data, sent the score to 96%. Bingo!</p>
                        <p>That's not the end though. BERT takes much longer to train and inference. Explainability
                            is
                            terrible, compared to a neat feature importance produced from traditional NLP. What's
                            the
                            advantage except for a better performance, which some business may decide against in
                            favour
                            of a faster training time and explainability?</p>
                        <p>I think this is essentially a cooking problem.</p>
                        <p>What??? I hear you ask.</p>
                        <p>Think of traditional NLP vs BERT as cooking pizza vs sour dough. Pizza is fast! For most
                            toppings, such as pepperoni and ham, you can just put straight on the bread (presume you
                            are
                            using pre-made dough). Into the oven it goes for 2 mins. Ping, ready and delicious.
                            However,
                            imagine for the same cooking process, you are then given some raw pepper. That's not
                            going
                            to get cooked in 2 mins, you need to roast it first! You say, hold on a second, I am not
                            stupid. If I see raw peppers, of course I know the extra preprocessing it needs. But
                            that's
                            not what model does after you have deployed it. You might not even notice some new
                            ingredients (raw peppers) has sneaked in! In machine learning lingo, your new data might
                            need extra features to work, and traditional NLP methods will require you to keep an eye
                            on
                            the data as it comes in. Your model's continuing performance depends on it.</p>
                        <p>Now think about sour dough. There is a mother dough you grow in your fridge. Every time
                            you
                            take it out, mix with new flour, water, salt, and return a proportion of this mix dough
                            back
                            to the fridge. That's your new sour dough. The secret of deliciousness is not only the
                            mother dough has been allowed to develop, but also has it seen the new ingredients. And
                            this
                            deliciousness carry through to all the food you made with the dough, sour dough bread,
                            pancake, even pizza! BERT is just like that. You can routinely fine tuning your BERT
                            parameters using the new data as it comes in, so it is kept updated on your new
                            documents,
                            writing styles, and vocabularies. All downstream tasks can all benefit from the updated
                            BERT
                            (as long as they are BERT based too), may it be classification or entity recognition, or
                            question answering. Better still, you don't even need labelled data to fine tune BERT,
                            AND
                            you can almost get away with smaller amount of labelled data for downstream tasks
                            because
                            most of the work ('understanding' language) has been done. How good is that?</p>

                        <p>What do you want to cook? Pizza or sour dough?</p>
                        <a href="https://github.com/ninjalu/doc-classification">Project code here</a>

                    </div>

                </div>
                <div class="d-flex flex-column flex-md-row justify-content-between">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">My data science journey</h3>
                        <p>Aug 2020</p>
                        <p>To start my data science journey while taking care of my toddler has been far away from
                            easy
                            or straightforward. There were excitement, setbacks, persistence, achievements and a lot
                            of
                            lack of sleep. I wouldn't change it for the world! I remember all the moments before I
                            was
                            about to present my work, finished late the night before, I felt proud, exhilarated and
                            inspired. I had spring in my step! To have received positive feedbacks from fellow data
                            scientists was the best. Now I know I can do it! I hope by sharing my <a
                                href="https://medium.com/@luolu.renmin/my-data-science-beginning-807d0b886a34">experience</a>,
                            I can inspire more staying at home mums to go out and embrace your next challenge,
                            whatever
                            it may be. It will be worth it!</p>
                    </div>
                </div>
            </div>
        </section>
        <hr class="m-0" />
        <!-- Interests-->
        <section class="resume-section" id="interests">
            <div class="resume-section-content">
                <h2 class="mb-5">Interests</h2>
                <p>In my spare time I enjoy gardening, garden design and floral design. I won "Best Front Garden" in our
                    community garden competition for my old front garden. Now I have transformed a 180 feet garden of
                    our new home. I started
                    arranging flowers for my friends and ultimately would love to use floral
                    arrangements to raise money for climate change charities.</p>
                <p class="mb-0">I am also the founder of Kingston Piano Club, a community music group where people share
                    their love for piano music to each other. We had our first concert in 2019.</p>

                <div>
                    <img style='height: 30%; width: 30%; object-fit: contain' src="assets/img/gardenat11.jpg" />
                    <img style='height: 30%; width: 30%; object-fit: contain' src="assets/img/IMG_5961.PNG" />
                    <img style='height: 30%; width: 30%; object-fit: contain' src="assets/img/IMG_5126.jpg" />

                </div>
            </div>
        </section>
    </div>
    <!-- Bootstrap core JS-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Third party plugin JS-->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
</body>

</html>